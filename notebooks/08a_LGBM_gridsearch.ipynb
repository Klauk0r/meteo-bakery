{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo Bakery - LightGBM feature selection and gridsearch\n",
    "In this notebook, we will implement a first version of a LightGBM model, test different feature sets, and perform gridsearch for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import meteo_utils as meteo\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_final.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate train and test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.year<2018]\n",
    "df_test = df[df.year>=2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Split Cross Validation\n",
    "Number of splits is set to 52 and test size to 7 days, thus representing a whole year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract an example time series for illustration purposes and perform TimeSeriesSplit\n",
    "ts = df_train[(df_train['branch']=='Metro') & (df_train['product']=='Brown Bread')]['turnover']\n",
    "tss = TimeSeriesSplit(n_splits=52, test_size=7, gap=0)\n",
    "\n",
    "fold=0\n",
    "# plot repeated train-validation folds to get an idea of TimeSeriesSplit functionality\n",
    "for train_i, val_i in tss.split(ts):\n",
    "    ts_train = ts.iloc[train_i]\n",
    "    ts_val = ts.iloc[val_i]\n",
    "\n",
    "    plt.figure(figsize=(10, 1))\n",
    "    ts_train[-500:].plot(c='blue', label='training')\n",
    "    ts_val.plot(c='red', label='validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Seasonal baseline\n",
    "The Naive Seasonal baseline model uses a drift of 7 days, i.e. it takes the sales of the preceding 7 days as a proxy for the sales on the upcoming 7 days. Whenever such a day includes a closing day due to holidays, the respective day is replaced by sales data 14 days ago. Whenever a closing day is contained in the forecasting window, the respective day is deleted and instead, a prediction is made on a reduced test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = meteo.crossval_naive(df_train, grouping_vars=['branch', 'product'], target='turnover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "We will now test LightGBM with different combinations of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = ['turnover_lag_7', 'turnover_lag_365', 'month_sin', 'month_cos', 'day_of_week', 'school_holiday', 'public_holiday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_time = meteo.crossval_lgbm(df_train, grouping_vars=['branch', 'product'], target='turnover', features=time_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic weather statistics (temperature, humidity, rain, snow)\n",
    "Here, will will add daily weather aggregate features as predictors to assess any add-on effect in addition to the temporal features. We will use mean temperature, humidity, rain, and snow as weather features since they appear most promising based on previous EDA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = ['turnover_lag_7', 'turnover_lag_365', 'month_sin', 'month_cos', 'day_of_week', 'school_holiday', 'public_holiday',\n",
    "                                    'temp_mean', 'humidity_mean', 'rain_1h_mean', 'snow_1h_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_weather = meteo.crossval_lgbm(df_train, grouping_vars=['branch', 'product'], target='turnover', features=weather_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including basic weather statistics slightly reduced the mean MAPE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic weather statistics and climatological days\n",
    "In addition to aggregated features, we calculated features for climatological days according to [DWD](https://www.dwd.de/DE/service/lexikon/Functions/glossar.html;jsessionid=EB2D3A27D634826A0176255436956DA7.live21064?lv2=101334&lv3=101452) based on our weather statistics. We first performed some basic EDA to test which climatological days could serve as potential predictors in the LGBM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize relative occurrence of climatological days depending on month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in ['day_icy', 'day_frosty', 'day_thunder', 'day_hot', 'day_clear','day_hazy', 'day_rainy', 'day_summer', 'day_murky']:\n",
    "    plt.figure(figsize=(7,1))\n",
    "    sns.barplot(data=df, y=day, x='month', color='white', edgecolor='blue')\n",
    "    plt.yticks(ticks=np.arange(0, 0.81, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize differences in sales for different product categories depending on climatological days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in ['day_icy', 'day_frosty', 'day_thunder', 'day_hot', 'day_clear','day_hazy', 'day_rainy', 'day_summer', 'day_murky']:\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    sns.barplot(data=df, x='product', y='turnover', edgecolor='blue', hue=day)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title=day, bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day frosty and Day icy measure similar weather conditions and have similar effects. The same holds true for day hot and day summer. However, day frosty and day summer have higher occurrence, so we will use these ones as predictors, as opposed to the other ones. \n",
    "\n",
    "Day rainy has almost no occurrence and almost no effect and is therefore not used as predictor. Day murky is also not used since it doesn´t have any clear effect and represents the counterpart to day clear. \n",
    "\n",
    "Day clear and day hazy don´t seem to have clear effects either, but are included as predictors at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_climat_features = ['turnover_lag_7', 'turnover_lag_365', 'month_sin', 'month_cos', 'day_of_week', 'school_holiday', 'public_holiday',\n",
    "                                    'temp_mean', 'humidity_mean', 'rain_1h_mean', 'snow_1h_mean', \n",
    "                                    'day_frosty', 'day_thunder', 'day_clear','day_hazy', 'day_summer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_climat = meteo.crossval_lgbm(df_train, grouping_vars=['branch', 'product'], target='turnover', features=weather_climat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_climat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using climatological days as additional predictors further slightly decreased the mean MAPE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic weather statistics, climatological days, seasonal deviations, daily changes and lead features\n",
    "Finally, we will also assess a set of weather features measuring seasonal deviations in weather, day-to-day changes, as well as 1-day lead weather features to assess effects of anticipated weather on the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_climat_dev_features = ['turnover_lag_7', 'turnover_lag_365', 'month_sin', 'month_cos', 'day_of_week', 'school_holiday', 'public_holiday',\n",
    "                                    'temp_mean', 'humidity_mean', 'rain_1h_mean', 'snow_1h_mean',\n",
    "                                                    'day_frosty', 'day_thunder', 'day_clear','day_hazy', 'day_summer',\n",
    "                                                    'temp_mean_dev', 'humidity_mean_dev', 'pressure_mean_dev', 'rain_1h_mean_dev', 'snow_1h_mean_dev',\n",
    "                                                    'temp_mean_change', 'pressure_mean_change', 'humidity_mean_change',\n",
    "                                                    'temp_mean_lead_1', 'rain_1h_mean_lead_1', 'snow_1h_mean_lead_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_dev = meteo.crossval_lgbm(df_train, grouping_vars=['branch', 'product'], target='turnover', features=weather_climat_dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including seasonal deviations, daily weather changes and lead features further notably reduced the mean MAPE score by almost 0.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch on LightGBM\n",
    "After identifying the best combination of features, we will perform hyperparameter tuning using GridSearch to further optimize LGBM forecasting performance. Specifically, we will test different boosting types, numbers of estimators, and different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hyperparameter dictionary for grid search\n",
    "lgbm_params = {\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.08, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize df for storing results from gridsearch\n",
    "grid_results = pd.DataFrame({'boosting_type': [], 'n_estimators': [], 'learning_rate': [], 'MAPE': []})\n",
    "\n",
    "for i, params in enumerate(product(lgbm_params['boosting_type'], lgbm_params['n_estimators'], lgbm_params['learning_rate'])):\n",
    "    print(params)\n",
    "\n",
    "    local_params = {\n",
    "        'boosting_type': params[0],\n",
    "        'n_estimators': int(params[1]),\n",
    "        'learning_rate': float(params[2])}\n",
    "    \n",
    "                \n",
    "    lgbm = LGBMRegressor(objective='regression', importance_type='gain', random_state=42, **local_params)\n",
    "    \n",
    "    # initialize empty list to compute average MAPE overall individual time series per hyperparameter configuration\n",
    "    mapes_local = []\n",
    "\n",
    "     # iterate over all individual series and perform cross-validation\n",
    "    for k, group in enumerate(product(df_train['branch'].unique(), df_train['product'].unique())):\n",
    "        # subselect time series\n",
    "        ts = df_train[(df_train['branch']==group[0]) & (df_train['product']==group[1])].copy()\n",
    "\n",
    "        # perform cross validation\n",
    "        tss = TimeSeriesSplit(n_splits=52, test_size=7, gap=0)\n",
    "\n",
    "        fold=0\n",
    "        scores = []\n",
    "        for train_i, val_i in tss.split(ts):\n",
    "\n",
    "            train = ts.iloc[train_i]\n",
    "            val = ts.iloc[val_i]\n",
    "                    \n",
    "            X_train = train[weather_climat_features]\n",
    "            X_val = val[weather_climat_features]\n",
    "            y_train = train['turnover']\n",
    "            y_val = val['turnover']\n",
    "\n",
    "            lgbm.fit(X_train, y_train)\n",
    "            y_pred = pd.Series(lgbm.predict(X_val))\n",
    "            # correct for holiday effects in validation set if necessary\n",
    "            # if holiday is in validation set, drop elements at corresponding index position in both y_val and y_pred\n",
    "            if 1 in y_val.unique():\n",
    "                idx_val = [i for i in range(len(y_val.tolist())) if y_val.tolist()[i]==1]\n",
    "                y_val = y_val.drop(y_val.index[idx_val])\n",
    "                y_pred = y_pred.drop(y_pred.index[idx_val])\n",
    "\n",
    "            mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "            scores.append(mape)\n",
    "        \n",
    "        # calculate mean MAPE score for individual time series\n",
    "        mean_score = np.mean(scores)\n",
    "        mapes_local.append(mean_score)\n",
    "    \n",
    "    grid_results.loc[i, 'boosting_type'] = params[0]\n",
    "    grid_results.loc[i, 'n_estimators'] = params[1]\n",
    "    grid_results.loc[i, 'learning_rate'] = params[2]\n",
    "    grid_results.loc[i, 'MAPE'] = np.mean(mapes_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest mean MAPE score (14.05%) was reached with the following hyperparameters:\n",
    "* boosting type: dart\n",
    "* number of estimators: 200\n",
    "* learning rate: 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results.to_csv('../models/LGBM_hyperparams.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5088fa60f7d34fb5f2ba3ff772c32280f8a6f8f3ea142d94c52ee17185bba4b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
