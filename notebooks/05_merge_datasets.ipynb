{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo Bakery - Combine datasets\n",
    "This notebook serves to combine sales data with the weather summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sales data\n",
    "sales = pd.read_excel('../data/neueFische_Umsaetze_Baeckerei.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data on engineered weather features\n",
    "weather_stats = pd.read_csv('../data/summary_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load holidays data and append to sales dataframe\n",
    "\n",
    "# school holidays from https://www.schulferien.org/oesterreich/ferien/2012/\n",
    "school_hols = pd.read_excel(\"../data/school_holidays.xlsx\")\n",
    "\n",
    "# public holidays from google search \"Feiertage Wien 'YEAR'\"\n",
    "public_hols = pd.read_excel(\"../data/public_holidays.xlsx\")\n",
    "public_hols.date = pd.to_datetime(public_hols.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Corona data\n",
    "corona = pd.read_excel(\"../data/corona-measures-vienna.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic information on datatypes and missings\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate location column based on branch\n",
    "# Filiale 1: U-Bahn\n",
    "# Filiale 2: Innenstadt\n",
    "# Filiale 3: Bahnhof\n",
    "\n",
    "sales['Branch'] = sales.Branch.apply(lambda x: 'Metro' if x==1 else 'Center' if x==2 else 'Train_Station')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three missing values in the sales data ('SoldTurnver')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "sales.rename(columns={'Branch': 'branch', 'PredictionGroupName': 'product', 'SoldTurnver': 'turnover'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time features from Date column\n",
    "sales['year'] = sales.Date.dt.year\n",
    "sales['month'] = sales.Date.dt.month\n",
    "sales['week'] = sales.Date.dt.week\n",
    "sales['day_of_month'] = sales.Date.dt.day\n",
    "sales['day_of_week'] = sales.Date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.rename(columns={'Date': 'date'}, inplace=True)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count dates per branch and product category\n",
    "sales.groupby(['branch', 'product'])['date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, not all dates are equally represented per group. This indicates that dates are not continuously progressing, but that there gaps present in the dates. Thus, there must be missing dates. Indeed, the first Covid19 lockdown has already removed from the data, representing one of possibly more gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a time series of consecutive dates as backbone\n",
    "To avoid such gaps, we will first generate a datetime column with consecutive gaps starting and ending with the first and last registered date. The other data will then be merged into that continuous date column, with gaps in certain columns being filled up with NaNs. These NaNs can be handled strategically during later analysis and modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = pd.DataFrame({'date':pd.date_range(sales.date.min(), sales.date.max())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.date.nunique())\n",
    "print(consec_dates.date.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.date.nunique() * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat the dates for each branch and product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates[['Metro', 'Center', 'Train_Station']] = 'Metro', 'Center', 'Train_Station'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.set_index('date', inplace=True)\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = consec_dates.stack().reset_index(name='branch').drop(columns=['level_1'])\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = sales['product'].unique()\n",
    "consec_dates[products] = products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.set_index(['date', 'branch'], inplace=True)\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = consec_dates.stack().reset_index(name='product').drop(columns=['level_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append holiday and Covid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append holidays to sales data by creating true/false columns\n",
    "sales[\"school_holiday\"] = sales[\"date\"].isin(school_hols[\"date\"])\n",
    "sales[\"public_holiday\"] = sales[\"date\"].isin(public_hols[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast lockdown times\n",
    "sales[\"lock\"] = 'open'\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2020-03-10\")) & (sales.date < pd.to_datetime(\"2020-04-14\")),\"lock\"] = \"lockdown\"\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2020-11-03\")) & (sales.date < pd.to_datetime(\"2020-11-17\")),\"lock\"] = \"lockdown_light\"\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2020-11-17\")) & (sales.date < pd.to_datetime(\"2020-12-06\")),\"lock\"] = \"lockdown\"\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2020-12-26\")) & (sales.date < pd.to_datetime(\"2021-02-07\")),\"lock\"] = \"lockdown\"\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2021-04-01\")) & (sales.date < pd.to_datetime(\"2021-05-02\")),\"lock\"] = \"lockdown\"\n",
    "sales.loc[(sales.date >= pd.to_datetime(\"2021-11-08\")) & (sales.date < pd.to_datetime(\"2021-12-31\")),\"lock\"] = \"lockdown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with weather statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse date to datetime\n",
    "weather_stats['date'] = pd.to_datetime(weather_stats['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "df_joined = sales.merge(weather_stats, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge sales into backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = consec_dates.merge(df_joined, on=['date', 'branch', 'product'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby(['branch', 'product'])['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export combined data to csv file\n",
    "df_full.to_csv('../data/data_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5088fa60f7d34fb5f2ba3ff772c32280f8a6f8f3ea142d94c52ee17185bba4b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
