{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo Bakery - Combine datasets\n",
    "This notebook serves to combine df_full data with the weather summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_full data\n",
    "sales = pd.read_excel('../data/neueFische_Umsaetze_Baeckerei.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data on engineered weather features\n",
    "weather_stats = pd.read_csv('../data/summary_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load holidays data\n",
    "\n",
    "# school holidays from https://www.schulferien.org/oesterreich/ferien/2012/\n",
    "school_hols = pd.read_excel(\"../data/school_holidays.xlsx\")\n",
    "\n",
    "# public holidays from google search \"Feiertage Wien 'YEAR'\"\n",
    "public_hols = pd.read_excel(\"../data/public_holidays.xlsx\")\n",
    "public_hols.date = pd.to_datetime(public_hols.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Corona data\n",
    "corona = pd.read_excel(\"../data/corona-measures-vienna.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic information on datatypes and missings\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate location column based on branch\n",
    "# Filiale 1: U-Bahn\n",
    "# Filiale 2: Innenstadt\n",
    "# Filiale 3: Bahnhof\n",
    "\n",
    "sales['Branch'] = sales.Branch.apply(lambda x: 'Metro' if x==1 else 'Center' if x==2 else 'Train_Station')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three missing values in the sales data ('SoldTurnver')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "sales.rename(columns={'Branch': 'branch', 'PredictionGroupName': 'product', 'SoldTurnver': 'turnover'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.rename(columns={'Date': 'date'}, inplace=True)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabel products\n",
    "sales['product'] = sales['product'].map({'Mischbrote':'Brown Bread',\n",
    "                                'Weizenbrötchen':'Wheat Rolls',\n",
    "                                'klassischer Kuchen':'Cakes',\n",
    "                                'handliches Gebäck':'Pastries',\n",
    "                                'herzhafter Snack':'Savoury Snack'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count dates per branch and product category\n",
    "sales.groupby(['branch', 'product'])['date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, not all dates are equally represented per group. This indicates that dates are not continuously progressing, but that there gaps present in the dates. Thus, there must be missing dates. Indeed, the first Covid19 lockdown has already removed from the data, representing one of possibly more gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a time series of consecutive dates as backbone\n",
    "To avoid such gaps, we will first generate a datetime column with consecutive gaps starting and ending with the first and last registered date. The other data will then be merged into that continuous date column, with gaps in certain columns being filled up with NaNs. These NaNs can be handled strategically during later analysis and modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = pd.DataFrame({'date':pd.date_range(sales.date.min(), sales.date.max())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.date.nunique())\n",
    "print(consec_dates.date.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.date.nunique() * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat the dates for each branch and product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates[['Metro', 'Center', 'Train_Station']] = 'Metro', 'Center', 'Train_Station'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.set_index('date', inplace=True)\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = consec_dates.stack().reset_index(name='branch').drop(columns=['level_1'])\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = sales['product'].unique()\n",
    "consec_dates[products] = products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.set_index(['date', 'branch'], inplace=True)\n",
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates = consec_dates.stack().reset_index(name='product').drop(columns=['level_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consec_dates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge sales into backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = consec_dates.merge(sales, on=['date', 'branch', 'product'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.groupby(['branch', 'product'])['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append additional time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time features from Date column\n",
    "df_full['year'] = df_full.date.dt.year\n",
    "df_full['month'] = df_full.date.dt.month\n",
    "df_full['week'] = df_full.date.dt.week\n",
    "df_full['day_of_month'] = df_full.date.dt.day\n",
    "df_full['day_of_week'] = df_full.date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append holiday and Covid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append holidays by creating true/false columns\n",
    "df_full[\"school_holiday\"] = df_full[\"date\"].isin(school_hols[\"date\"])\n",
    "df_full[\"public_holiday\"] = df_full[\"date\"].isin(public_hols[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast lockdown times\n",
    "df_full[\"lock\"] = 'open'\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2020-03-10\")) & (df_full.date < pd.to_datetime(\"2020-04-14\")),\"lock\"] = \"lockdown\"\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2020-11-03\")) & (df_full.date < pd.to_datetime(\"2020-11-17\")),\"lock\"] = \"lockdown_light\"\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2020-11-17\")) & (df_full.date < pd.to_datetime(\"2020-12-06\")),\"lock\"] = \"lockdown\"\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2020-12-26\")) & (df_full.date < pd.to_datetime(\"2021-02-07\")),\"lock\"] = \"lockdown\"\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2021-04-01\")) & (df_full.date < pd.to_datetime(\"2021-05-02\")),\"lock\"] = \"lockdown\"\n",
    "df_full.loc[(df_full.date >= pd.to_datetime(\"2021-11-08\")) & (df_full.date < pd.to_datetime(\"2021-12-31\")),\"lock\"] = \"lockdown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with weather statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse date to datetime\n",
    "weather_stats['date'] = pd.to_datetime(weather_stats['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "df_joined = df_full.merge(weather_stats, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export combined data to csv file\n",
    "df_joined.to_csv('../data/data_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51c3f431670d74800037e338e4014a8e6dc9aaef0885bb053b0cd3ee83d5b009"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
