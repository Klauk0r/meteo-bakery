{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteo Bakery - Comparing forecasting models\n",
    "In this notebook, we compare several forecasting models on our multiple time series, i.e. linear regression, RandomForest, LightGBM and CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils import missing_values\n",
    "from darts.metrics import rmse, mape\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "from darts.models import RegressionModel\n",
    "from darts.models.forecasting.random_forest import RandomForest\n",
    "from darts.models.forecasting.gradient_boosted_model import LightGBMModel\n",
    "from darts.models.forecasting.catboost_model import CatBoostModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked = pd.read_csv('../data/data_combined.csv')\n",
    "df_stacked['date'] = pd.to_datetime(df_stacked['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data before Covid19\n",
    "df_stacked = df_stacked[df_stacked.year < 2020]\n",
    "df_stacked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate a multiple time series object\n",
    "Using darts.TimeSeries class, we generate a multiple time series object from a stacked / grouped time series df, essentially representing a list of all individual time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df into multiple time series object\n",
    "series_multi = TimeSeries.from_group_dataframe(df=df_stacked, group_cols=['branch', 'product'], \n",
    "                                        value_cols=['turnover'], time_col='date', freq='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs in each series by interpolation from darts imputation functionalities using list comprehension\n",
    "series_multi_nan = [missing_values.fill_missing_values(series_multi[i], fill='auto') for i in range(len(series_multi))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### access grouping IDs for each time series using static_covariates attribute\n",
    "Grouping IDs can be assessed through static_covariates attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of series in multiple series object\n",
    "print(f\"\\n{len(series_multi)} series were extracted from the input DataFrame\\n\")\n",
    "\n",
    "# iterate over each time series, print static_covariates (i.e. group IDs) and plot individual time series\n",
    "for i, ts in enumerate(series_multi_nan):\n",
    "    ts['turnover'].plot(label=f'{ts.static_covariates.iloc[:, 0][0]} | {ts.static_covariates.iloc[:, 1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate covariate series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.columns[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a multiple covariates time series object\n",
    "covariates_multi = TimeSeries.from_group_dataframe(df=df_stacked, group_cols=['branch', 'product'], \n",
    "                                        value_cols=['month', 'day_of_week', 'school_holiday', 'public_holiday',\n",
    "                                        'clear_total', 'cloudy_total', 'foggy_total', 'rainy_total', 'snowy_total'], \n",
    "                                        time_col='date', freq='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale covariates using MinMax scaling\n",
    "scaler = Scaler()\n",
    "\n",
    "covariates_scaled = scaler.fit_transform(covariates_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_scaled[0].components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility function for plotting scaled covariates\n",
    "def check_scaling(series, component):\n",
    "    for i in range(len(series)):\n",
    "        series[i][component].plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_scaling(covariates_scaled, 'temp_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split by slicing each series within list using list comprehension\n",
    "train = [series_multi_nan[i][:-364] for i in range(len(series_multi_nan))] # extract all time points except for last year\n",
    "val = [series_multi_nan[i][-364:-357] for i in range(len(series_multi_nan))] # extract the next 7 days from end of training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use historical forecasts to compare models w/ and w/o covariates\n",
    "In order to assess changes in prediction accuracy following inclusion of covariates, we will design a utility function that iterates over a multiple time series object and for each time series performs a historical forecast for a model w/o covariates and w/ covariates. Here, we will specifically implement future covariates, such as months, day_of_week, holidays and weather forecasts.\n",
    "\n",
    "The forecasting horizon will be set to 7 days by default. Similarly, the stride will be set to 7 days by default, thus the training set for historical forecasts will always increase by 7 days.\n",
    "\n",
    "For comparison, we will compute both RMSE and MAPE from those forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility function for comparing historical forecasts on multiple time series between models w/ and w/o covariates\n",
    "def validate_historically(model, model_cov, multiple_series, future_covariates=None, forecast_horizon=7, stride=7, split=0.8, show_output=True):\n",
    "\n",
    "    # initialize dataframe for evaluation scores\n",
    "    scores = pd.DataFrame({'group': [], 'RMSE': [], 'RMSE_covariates': [], 'MAPE': [], 'MAPE_covariates': []})\n",
    "\n",
    "    # backtest the model on the last 50% of the series\n",
    "    # iterate over every series in multiple time series object\n",
    "    for i, series in enumerate(multiple_series):\n",
    "        # perform historical forecasts on model w/o covariates and save result\n",
    "        backtest_wo = model.historical_forecasts(series=series, \n",
    "                                          past_covariates=None,\n",
    "                                          future_covariates=None,\n",
    "                                          start=split, \n",
    "                                          stride=stride,\n",
    "                                          retrain=True,\n",
    "                                          verbose=show_output, \n",
    "                                          forecast_horizon=forecast_horizon)\n",
    "        # perform historical forecasts on model w/ covariates and save result\n",
    "        backtest_cov = model_cov.historical_forecasts(series=series, \n",
    "                                          past_covariates=None,\n",
    "                                          future_covariates=future_covariates[i],\n",
    "                                          start=split, \n",
    "                                          stride=stride,\n",
    "                                          retrain=True,\n",
    "                                          verbose=show_output, \n",
    "                                          forecast_horizon=forecast_horizon)\n",
    "\n",
    "        \n",
    "        # calculate RMSE and MAPE for predictions w/ and w/o covariates\n",
    "        RMSE_wo = rmse(series, backtest_wo).round(2)\n",
    "        MAPE_wo = mape(series, backtest_wo).round(2)\n",
    "\n",
    "        RMSE_cov = rmse(series, backtest_cov).round(2)\n",
    "        MAPE_cov = mape(series, backtest_cov).round(2)\n",
    "\n",
    "        # append scores\n",
    "        scores.loc[i, 'group'] = f'{series.static_covariates.iloc[:, 0][0]} | {series.static_covariates.iloc[:, 1][0]}'\n",
    "        scores.loc[i, 'RMSE'] = RMSE_wo\n",
    "        scores.loc[i, 'MAPE'] = MAPE_wo\n",
    "        scores.loc[i, 'RMSE_covariates'] = RMSE_cov\n",
    "        scores.loc[i, 'MAPE_covariates'] = MAPE_cov\n",
    "\n",
    "        if show_output:\n",
    "            #plot actual series values\n",
    "            series[int(len(series)*split):].plot()\n",
    "            # plot predicted values from historical model forecasts w/o covariates on top\n",
    "            backtest_wo.plot(label='fh=7 - w/o covariates')\n",
    "            # plot predicted values from historical model forecasts w/o covariates on top\n",
    "            backtest_cov.plot(label='fh=7 - w/ covariates')\n",
    "            # give title based on respective time series group IDs\n",
    "            plt.title(f'{series.static_covariates.iloc[:, 0][0]} | {series.static_covariates.iloc[:, 1][0]}')\n",
    "            plt.show()\n",
    "\n",
    "            # print evaluation scores\n",
    "            print(f'Backtest w/o covariates: RMSE = {RMSE_wo}, MAPE = {MAPE_wo}')\n",
    "            print(f'Backtest w/ covariates: RMSE = {RMSE_cov}, MAPE = {MAPE_cov}')\n",
    "\n",
    "    # calculate mean scores\n",
    "    scores.loc[i+1, 'group'] = 'mean'\n",
    "    scores.loc[i+1, ['RMSE', 'RMSE_covariates', 'MAPE', 'MAPE_covariates']] = [scores[x].mean().round(2) for x in ['RMSE', 'RMSE_covariates', 'MAPE', 'MAPE_covariates']]\n",
    "    \n",
    "    scores.set_index('group', inplace=True)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Linear Regression models\n",
    "\n",
    "# w/o covariates\n",
    "model = RegressionModel(lags=[-7, -364],\n",
    "                    model=LinearRegression())\n",
    "\n",
    "# w/ covariates\n",
    "model_cov = RegressionModel(lags=[-7, -364], \n",
    "                    model=LinearRegression(), lags_future_covariates=[0]) # future covariates without lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lm = validate_historically(model, model_cov, train, future_covariates=covariates_scaled, stride=28, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RandomForest models\n",
    "\n",
    "# w/o covariates\n",
    "rf = RandomForest(lags=[-7, -364]) # future covariates without lag\n",
    "\n",
    "# w/ covariates\n",
    "rf_cov = RandomForest(lags=[-7, -364], lags_future_covariates=[0]) # future covariates without lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = validate_historically(rf, rf_cov, train, future_covariates=covariates_scaled, stride=28, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate LightGBM models\n",
    "\n",
    "# w/o covariates\n",
    "lgbm = LightGBMModel(lags=[-7, -364]) \n",
    "\n",
    "# w/ covariates\n",
    "lgbm_cov = LightGBMModel(lags=[-7, -364], lags_future_covariates=[0]) # future covariates without lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lgbm = validate_historically(lgbm, lgbm_cov, train, future_covariates=covariates_scaled, stride=28, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CatBoost models\n",
    "\n",
    "# w/o covariates\n",
    "catb = CatBoostModel(lags=[-7, -364]) \n",
    "\n",
    "# w/ covariates\n",
    "catb_cov = CatBoostModel(lags=[-7, -364], lags_future_covariates=[0]) # future covariates without lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_catb = validate_historically(catb, catb_cov, train, future_covariates=covariates_scaled, stride=28, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores(dataframes, model_names, component):\n",
    "    \n",
    "    # initialize dataframe\n",
    "    scores = pd.DataFrame({'model': [], 'RMSE': [], 'RMSE_covariates': [], 'MAPE': [], 'MAPE_covariates': []})\n",
    "    \n",
    "    # append data\n",
    "    scores['model'] = model_names\n",
    "    scores['RMSE'] = [df.loc[component, 'RMSE'] for df in dataframes]\n",
    "    scores['RMSE_covariates'] = [df.loc[component, 'RMSE_covariates'] for df in dataframes]\n",
    "    scores['MAPE'] = [df.loc[component, 'MAPE'] for df in dataframes]\n",
    "    scores['MAPE_covariates'] = [df.loc[component, 'MAPE_covariates'] for df in dataframes]\n",
    "\n",
    "    scores.set_index('model', inplace=True)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [scores_lm, scores_rf, scores_lgbm, scores_catb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = combine_scores(models, ['lm', 'rf', 'lgbm', 'catb'], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluion\n",
    "Gradient boosting models such as LightGBM seem to make best use of covariates, as evidenced by the strongest reduction in RMSE and MAPE after covariate inclusion. However, they are still performing worse than a simple linear regression model.\n",
    "\n",
    "We will perform hyperparameter tuning on LightGBM using GridSearch to optimize forecasts.\n",
    "\n",
    "LightGBM default parameters:\n",
    "* n_estimators: 100\n",
    "* boosting type: gdbt\n",
    "* learning rate: 0.1\n",
    "* num_leaves: 31\n",
    "* max_depth: -1 (i.e. no limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hyperparameter dictionary for grid search\n",
    "lgbm_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'boosting_type': ['dart'], # supposedly best boosting type\n",
    "    'lags_future_covariates': [[0]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate LightGBM model w/ covariates\n",
    "lgbm_cov = LightGBMModel(lags=[-7, -364], lags_future_covariates=[0], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines if you want to perform gridsearch, but takes rather long\n",
    "#grid_results = pd.DataFrame({'group': [], 'best_model': [], 'score': []})\n",
    "#\n",
    "#for i, series in enumerate(train):\n",
    "#\n",
    "#    best_model = lgbm_cov.gridsearch(series=series, parameters=lgbm_params, future_covariates=covariates_scaled[i],\n",
    "#                                            forecast_horizon=7, stride=28, start=0.8, verbose=True,\n",
    "#                                            metric=mape, reduction=np.mean)\n",
    "#    # print results of best local model\n",
    "#    print(best_model)\n",
    "#\n",
    "#    # append scores\n",
    "#    grid_results.loc[i, 'group'] = f'{series.static_covariates.iloc[:, 0][0]} | {series.static_covariates.iloc[:, 1][0]}'\n",
    "#    grid_results.loc[i, 'best_model'] = str(best_model[1])\n",
    "#    grid_results.loc[i, 'score'] = best_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5088fa60f7d34fb5f2ba3ff772c32280f8a6f8f3ea142d94c52ee17185bba4b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
