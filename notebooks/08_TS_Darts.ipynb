{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data packages. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Viz. \n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from calendar import monthrange\n",
    "from calendar import month_name\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing, VARIMA, NBEATSModel, TFTModel, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_darts = df[df.year<2020].query('branch==\"Metro\" and product==\"Mischbrote\"')\n",
    "df_darts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = TimeSeries.from_dataframe(df_darts, 'date', 'turnover', freq='D', fill_missing_dates=True)[-365*4:-365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = series[:-365], series[-365:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialSmoothing()\n",
    "model.fit(train)\n",
    "prediction = model.predict(len(val), num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot()\n",
    "prediction.plot(label=\"forecast\", low_quantile=0.45, high_quantile=0.55)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darts II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we _might_ need the unstacked dataset after all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstack_time_series(df, index, groups, target):\n",
    "    \n",
    "    # create the individual combinations df\n",
    "    df_groups = df.pivot(index=index, columns=groups, values=target)\n",
    "    df_groups.columns = df_groups.columns.to_flat_index().map('{0[0]} | {0[1]}'.format)\n",
    "\n",
    "    # create df for first group, use agg(pd.Series.sum) instead of .sum to enable skipna, otherwise NaN rows will add up to 0\n",
    "    df_01 = df.groupby([index, groups[0]])[target] \\\n",
    "                        .agg(pd.Series.sum, skipna=False) \\\n",
    "                        .reset_index(drop=False) \\\n",
    "                        .pivot(index=index, columns=groups[0], values=target)\n",
    "\n",
    "    # create df for second group\n",
    "    df_02 = df.groupby([index, groups[1]])[target] \\\n",
    "                        .agg(pd.Series.sum, skipna=False)\\\n",
    "                        .reset_index(drop=False) \\\n",
    "                        .pivot(index=index, columns=groups[1], values=target)\n",
    "\n",
    "    # create the total level df\n",
    "    df_total = df.groupby(index)[target] \\\n",
    "                .agg(pd.Series.sum, skipna=False)\\\n",
    "                .to_frame() \\\n",
    "                .rename(columns={target: 'total'})\n",
    "\n",
    "    # join the DataFrames\n",
    "    df_unstacked = df_total.join(df_01) \\\n",
    "                                .join(df_02) \\\n",
    "                                .join(df_groups)\n",
    "    df_unstacked.index = pd.to_datetime(df_unstacked.index)\n",
    "    return df_unstacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstacked = unstack_time_series(df, 'date', ['branch', 'product'], 'turnover')[:'2020-01-01'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hierarchy for targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variables\n",
    "df['product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "hierarchy = dict()\n",
    "\n",
    "# Fill in grouping by branch\n",
    "for branch in df.branch.unique():\n",
    "    hierarchy[branch] = [\"total\"]\n",
    "\n",
    "# Fill in grouping by product\n",
    "for good in df['product'].unique():\n",
    "    hierarchy[good] = [\"total\"]\n",
    "\n",
    "# Fill in grouping by (product, branch)\n",
    "for good, branch in product(df['product'].unique(), df.branch.unique()):\n",
    "    hierarchy[\"{} | {}\".format(branch, good)] = [branch, good]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['total', 'Center', 'Metro', 'Train_Station', 'Mischbrote',\n",
    "       'Weizenbrötchen', 'handliches Gebäck', 'herzhafter Snack',\n",
    "       'klassischer Kuchen', 'Metro | Mischbrote', 'Metro | Weizenbrötchen',\n",
    "       'Metro | klassischer Kuchen', 'Metro | handliches Gebäck',\n",
    "       'Metro | herzhafter Snack', 'Center | Mischbrote',\n",
    "       'Center | Weizenbrötchen', 'Center | klassischer Kuchen',\n",
    "       'Center | handliches Gebäck', 'Center | herzhafter Snack',\n",
    "       'Train_Station | Mischbrote', 'Train_Station | Weizenbrötchen',\n",
    "       'Train_Station | klassischer Kuchen',\n",
    "       'Train_Station | handliches Gebäck', 'Train_Station | herzhafter Snack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = df_unstacked.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create TimeSeries with hierarchy\n",
    "series = TimeSeries.from_dataframe(df=df_unstacked, time_col='date', value_cols=targets, hierarchy=hierarchy)\n",
    "\n",
    "from darts.utils import missing_values\n",
    "\n",
    "series = missing_values.fill_missing_values(series, fill='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = series[:-365], series[-365:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel(lags=365)\n",
    "model.fit(train)\n",
    "pred = model.predict(n=len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series.plot()\n",
    "components_to_show = ['Center', 'Metro', 'Train_Station']\n",
    "plt.figure(figsize=(28, 7))\n",
    "series[components_to_show].plot(lw=1)\n",
    "pred[components_to_show].plot(lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mape:',round(mape(val,pred),4))\n",
    "print('rmse:',round(rmse(val, pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Covariates (weather data, hintedy-hint!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stats = pd.read_csv('../data/summary_stats.csv')\n",
    "weather_stats.date = pd.to_datetime(weather_stats.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_unstacked.merge(weather_stats, on=['date'], how='left')\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined[(df_joined.date>'2019-10-01')&(df_joined.date<'2019-10-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils import missing_values\n",
    "\n",
    "series = missing_values.fill_missing_values(series, fill='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a covariate series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create covariate series\n",
    "covariates = TimeSeries.from_dataframe(df=df_joined, time_col='date', value_cols=['temp_mean', 'clouds_mean', 'rain_1h_mean', 'snow_1h_mean'])\n",
    "\n",
    "covariates = missing_values.fill_missing_values(series, fill='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel(lags=[-7,-365], lags_future_covariates=[0])\n",
    "model.fit(train, future_covariates=covariates)\n",
    "pred = model.predict(n=len(val), future_covariates=covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series.plot()\n",
    "#components_to_show = ['Center', 'Metro', 'Train_Station']\n",
    "plt.figure(figsize=(28, 7))\n",
    "series[components_to_show].plot(lw=1)\n",
    "pred[components_to_show].plot(lw=2)\n",
    "#plt.ylim((-2000,8000))\n",
    "#plt.xlim((0,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mape:',round(mape(val,pred),4))\n",
    "print('rmse:',round(rmse(val, pred),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51c3f431670d74800037e338e4014a8e6dc9aaef0885bb053b0cd3ee83d5b009"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
